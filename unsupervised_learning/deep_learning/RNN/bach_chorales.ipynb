{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "The Bach chorales dataset is made of 382 chorales composed by Johann Sebastian Bach. Each chorale is 100 to 640 time steps long, and each time step contains 4 integers, where each integer corresponds to a note's index on a piano.\n",
    "\n",
    "We are trying to train a model that can predict the next four notes from a sequene of time steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfiles(path):\n",
    "    X = []\n",
    "    for filename in os.listdir(path):\n",
    "        file_path = os.path.join(path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        X.append(df.values.tolist())\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "train = readfiles(\"./jsb_chorales/train\")\n",
    "test = readfiles(\"./jsb_chorales/test\")\n",
    "valid = readfiles(\"./jsb_chorales/valid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229 train sequences\n",
      "76 valid sequences\n",
      "77 test sequences\n"
     ]
    }
   ],
   "source": [
    "print(len(train), 'train sequences')\n",
    "print(len(valid), 'valid sequences')\n",
    "print(len(test), 'test sequences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sequences do not have uniform length. For efficient computation, it is best to pad the sequences so that they have the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516\n",
      "576\n",
      "640\n"
     ]
    }
   ],
   "source": [
    "def maxlen(set):\n",
    "    return max(len(seq) for seq in set)\n",
    "print(maxlen(train))\n",
    "print(maxlen(valid))\n",
    "print(maxlen(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 576 # setting maxlen to the longest sequence in the valid set\n",
    "\n",
    "train_pad = pad_sequences(train, dtype=np.float32, maxlen=maxlen)\n",
    "valid_pad = pad_sequences(valid, dtype=np.float32, maxlen=maxlen)\n",
    "test_pad = pad_sequences(test, dtype=np.float32, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_pad shape: (229, 576, 4)\n",
      "valid_pad shape: (76, 576, 4)\n",
      "test_pad shape: (77, 576, 4)\n"
     ]
    }
   ],
   "source": [
    "print('train_pad shape:', train_pad.shape)\n",
    "print('valid_pad shape:', valid_pad.shape)\n",
    "print('test_pad shape:', test_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train_pad[:, :-1], train_pad[:, -1:]\n",
    "x_valid, y_valid = valid_pad[:, :-1], valid_pad[:, -1:]\n",
    "x_test, y_test = test_pad[:, :-1], test_pad[:, -1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a RNN\n",
    "\n",
    "## SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn = Sequential([\n",
    "    keras.Input(shape=(None, train_pad.shape[-1])),\n",
    "    SimpleRNN(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model_rnn.compile(loss=\"mse\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to split the data into x_train, y_train, x_valid, y_valid, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 3331.5400 - val_loss: 3389.9473\n",
      "Epoch 2/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 3307.6670 - val_loss: 3389.9473\n",
      "Epoch 3/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 3325.5991 - val_loss: 3389.9473\n",
      "Epoch 4/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 3286.7603 - val_loss: 3389.9473\n",
      "Epoch 5/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 3288.3254 - val_loss: 3389.9473\n",
      "Epoch 6/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 3311.0630 - val_loss: 3389.9473\n",
      "Epoch 7/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 3305.2632 - val_loss: 3389.9473\n",
      "Epoch 8/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 3304.0364 - val_loss: 3389.9473\n",
      "Epoch 9/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 3319.3000 - val_loss: 3389.9473\n",
      "Epoch 10/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 3332.2739 - val_loss: 3389.9473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a597c10dd0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rnn.fit(x_train, y_train, batch_size=5, epochs=10, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
