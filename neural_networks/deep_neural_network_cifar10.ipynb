{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network on the CIFAR10 Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar = keras.datasets.cifar10\n",
    "(x_train_full, y_train_full), (x_test, y_test) = cifar.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_full.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train_full.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train_full[1])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_full[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "x_valid = x_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for model code reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callbacks(checkpoint_filepath, model_logs_directory):\n",
    "    early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "    model_checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_best_only=True)\n",
    "    run_index = 1 # increment every time you train the model\n",
    "    run_logdir = os.path.join(os.curdir, model_logs_directory + \"/my_cifar10_logs\", \"run_bn_{:03d}\".format(run_index))\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "    callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "    return callbacks\n",
    "\n",
    "def evauluate_model(model, x_test, y_test):\n",
    "    results = model.evaluate(x_test, y_test)\n",
    "    print(\"test loss, test accuracy:\", results)\n",
    "\n",
    "def build_model(hidden_layers=1, neurons=10, learning_rate=3e03, input_shape=[8], activation=\"relu\", loss_func = \"mse\", optimizer=None):\n",
    "    if optimizer is None:\n",
    "        print(\"No optimizer given. Using SGD optimizer with 3e-3 learning rate\")\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=3e-3)\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=input_shape))\n",
    "\n",
    "    for _ in range(hidden_layers):\n",
    "        model.add(keras.layers.Dense(neurons, activation=activation))\n",
    "\n",
    "    model.add(keras.layers.Dense(10))\n",
    "\n",
    "    \n",
    "    model.compile(loss=loss_func, optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# static, throughout the notebook\n",
    "layers = 20\n",
    "neurons = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dev\\Machine_Learning\\tackleml\\env\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(layers):\n",
    "    model.add(keras.layers.Dense(neurons,\n",
    "                                activation=\"elu\",\n",
    "                                kernel_initializer=\"he_normal\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is He Normal Initialization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A weight initialization used with ReLU and its variants. Helps avoid issues like vanishing or exploding gradrients during training, which leads to faster convergence and better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross entropy loss function is an optimization function \n",
    "# which is used in case of training a classification model \n",
    "# which classifies the data by predicting the probability \n",
    "# of whether the data belongs to one class or the other class\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-5)\n",
    "model.compile(loss=loss_fn, optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output layer\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-5)\n",
    "model.compile(\n",
    "    loss=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = \"my_cifar10_model.keras\"\n",
    "model_logs_directory = \"my_model_logs\"\n",
    "\n",
    "callbacks = create_callbacks(checkpoint_filepath, model_logs_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.0990 - loss: 2.3478 - val_accuracy: 0.1038 - val_loss: 2.3397\n",
      "Epoch 2/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0989 - loss: 2.3313 - val_accuracy: 0.1038 - val_loss: 2.3270\n",
      "Epoch 3/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0989 - loss: 2.3229 - val_accuracy: 0.1038 - val_loss: 2.3186\n",
      "Epoch 4/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0992 - loss: 2.3145 - val_accuracy: 0.1038 - val_loss: 2.3131\n",
      "Epoch 5/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0991 - loss: 2.3104 - val_accuracy: 0.1038 - val_loss: 2.3095\n",
      "Epoch 6/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0969 - loss: 2.3072 - val_accuracy: 0.1038 - val_loss: 2.3072\n",
      "Epoch 7/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1004 - loss: 2.3056 - val_accuracy: 0.1038 - val_loss: 2.3057\n",
      "Epoch 8/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0996 - loss: 2.3037 - val_accuracy: 0.0920 - val_loss: 2.3047\n",
      "Epoch 9/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1014 - loss: 2.3034 - val_accuracy: 0.0920 - val_loss: 2.3041\n",
      "Epoch 10/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1019 - loss: 2.3031 - val_accuracy: 0.0920 - val_loss: 2.3036\n",
      "Epoch 11/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1012 - loss: 2.3028 - val_accuracy: 0.0920 - val_loss: 2.3034\n",
      "Epoch 12/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0977 - loss: 2.3029 - val_accuracy: 0.0920 - val_loss: 2.3032\n",
      "Epoch 13/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1042 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3031\n",
      "Epoch 14/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1012 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3030\n",
      "Epoch 15/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1022 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3029\n",
      "Epoch 16/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0994 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3029\n",
      "Epoch 17/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1011 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 18/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1008 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 19/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1006 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 20/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1008 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 21/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1003 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 22/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1018 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 23/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1016 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 24/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0995 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 25/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0986 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 26/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1041 - loss: 2.3025 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 27/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0994 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 28/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0964 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 29/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1016 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 30/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1042 - loss: 2.3025 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 31/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0994 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 32/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0987 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 33/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1019 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3027\n",
      "Epoch 34/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1007 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 35/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1001 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 36/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1001 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 37/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1022 - loss: 2.3025 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 38/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.0998 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 39/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1015 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 40/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1003 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 41/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1008 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3027\n",
      "Epoch 42/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.0982 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 43/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1024 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 44/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1020 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3027\n",
      "Epoch 45/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1039 - loss: 2.3025 - val_accuracy: 0.0920 - val_loss: 2.3027\n",
      "Epoch 46/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1019 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3027\n",
      "Epoch 47/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.0989 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 48/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1021 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 49/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.0984 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 50/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1027 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 51/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1028 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 52/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0989 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 53/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0999 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 54/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0999 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 55/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1036 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 56/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1017 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 57/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.0995 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 58/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1025 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 59/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1006 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 60/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1030 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 61/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1007 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 62/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1006 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 63/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0986 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 64/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1020 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 65/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1006 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3028\n",
      "Epoch 66/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1009 - loss: 2.3026 - val_accuracy: 0.0920 - val_loss: 2.3027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1ce84f4c1d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100,\n",
    "          validation_data=(x_valid, y_valid),\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1019 - loss: 2.3026\n",
      "test loss, test accuracy: [2.3027446269989014, 0.09200000017881393]\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(checkpoint_filepath)\n",
    "evauluate_model(model=model, x_test=x_valid, y_test=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model sucks, lets optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Dev\\Machine_Learning\\tackleml\\env\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 9ms/step - accuracy: 0.2910 - loss: 1.9719 - val_accuracy: 0.4062 - val_loss: 1.6749\n",
      "Epoch 2/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.4013 - loss: 1.6821 - val_accuracy: 0.4214 - val_loss: 1.6052\n",
      "Epoch 3/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.4352 - loss: 1.5905 - val_accuracy: 0.4358 - val_loss: 1.5776\n",
      "Epoch 4/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.4630 - loss: 1.5192 - val_accuracy: 0.4534 - val_loss: 1.5430\n",
      "Epoch 5/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.4866 - loss: 1.4554 - val_accuracy: 0.4604 - val_loss: 1.5235\n",
      "Epoch 6/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.5076 - loss: 1.3989 - val_accuracy: 0.4608 - val_loss: 1.5346\n",
      "Epoch 7/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5260 - loss: 1.3478 - val_accuracy: 0.4680 - val_loss: 1.5413\n",
      "Epoch 8/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.5404 - loss: 1.2994 - val_accuracy: 0.4668 - val_loss: 1.5625\n",
      "Epoch 9/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.5595 - loss: 1.2553 - val_accuracy: 0.4672 - val_loss: 1.5919\n",
      "Epoch 10/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.5752 - loss: 1.2098 - val_accuracy: 0.4702 - val_loss: 1.5877\n",
      "Epoch 11/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5918 - loss: 1.1700 - val_accuracy: 0.4610 - val_loss: 1.6459\n",
      "Epoch 12/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6031 - loss: 1.1344 - val_accuracy: 0.4618 - val_loss: 1.6941\n",
      "Epoch 13/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6128 - loss: 1.1025 - val_accuracy: 0.4582 - val_loss: 1.7103\n",
      "Epoch 14/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6285 - loss: 1.0669 - val_accuracy: 0.4632 - val_loss: 1.7301\n",
      "Epoch 15/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6353 - loss: 1.0396 - val_accuracy: 0.4634 - val_loss: 1.7559\n",
      "Epoch 16/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6466 - loss: 1.0091 - val_accuracy: 0.4558 - val_loss: 1.7908\n",
      "Epoch 17/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6588 - loss: 0.9779 - val_accuracy: 0.4536 - val_loss: 1.8183\n",
      "Epoch 18/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6684 - loss: 0.9514 - val_accuracy: 0.4602 - val_loss: 1.8333\n",
      "Epoch 19/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6799 - loss: 0.9257 - val_accuracy: 0.4550 - val_loss: 1.8778\n",
      "Epoch 20/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - accuracy: 0.6858 - loss: 0.9062 - val_accuracy: 0.4448 - val_loss: 1.8894\n",
      "Epoch 21/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - accuracy: 0.6950 - loss: 0.8774 - val_accuracy: 0.4456 - val_loss: 1.9762\n",
      "Epoch 22/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.7041 - loss: 0.8552 - val_accuracy: 0.4548 - val_loss: 1.9518\n",
      "Epoch 23/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.7123 - loss: 0.8293 - val_accuracy: 0.4418 - val_loss: 2.0262\n",
      "Epoch 24/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.7181 - loss: 0.8130 - val_accuracy: 0.4498 - val_loss: 2.0629\n",
      "Epoch 25/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.7253 - loss: 0.7952 - val_accuracy: 0.4434 - val_loss: 2.0253\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4636 - loss: 1.5279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.523534893989563, 0.4603999853134155]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "for _ in range(layers):\n",
    "    model.add(keras.layers.Dense(neurons, kernel_initializer=\"he_normal\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"elu\"))\n",
    "\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "checkpoint_filepath = \"my_cifar10_bn_model.keras\"\n",
    "model_logs_directory = \"my_model_logs\"\n",
    "\n",
    "callbacks = create_callbacks(checkpoint_filepath=checkpoint_filepath, model_logs_directory=model_logs_directory)\n",
    "\n",
    "model.fit(x_train, y_train, epochs=100,\n",
    "          validation_data=(x_valid, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(checkpoint_filepath)\n",
    "model.evaluate(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4636 - loss: 1.5279\n",
      "test loss, test accuracy: [1.523534893989563, 0.4603999853134155]\n"
     ]
    }
   ],
   "source": [
    "evauluate_model(model=model, x_test=x_valid, y_test=y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(layers):\n",
    "    model.add(keras.layers.Dense(neurons,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=7e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "checkpoint_filepath = \"my_cifar10_selu_model.keras\"\n",
    "model_logs_directory = \"my_model_logs\"\n",
    "\n",
    "callbacks = create_callbacks(checkpoint_filepath, model_logs_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.2789 - loss: 2.0279 - val_accuracy: 0.3526 - val_loss: 1.7937\n",
      "Epoch 2/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3797 - loss: 1.7283 - val_accuracy: 0.4024 - val_loss: 1.7286\n",
      "Epoch 3/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4248 - loss: 1.6235 - val_accuracy: 0.4148 - val_loss: 1.7112\n",
      "Epoch 4/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4464 - loss: 1.5548 - val_accuracy: 0.4522 - val_loss: 1.5683\n",
      "Epoch 5/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4758 - loss: 1.4942 - val_accuracy: 0.4518 - val_loss: 1.5864\n",
      "Epoch 6/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4929 - loss: 1.4473 - val_accuracy: 0.4594 - val_loss: 1.5852\n",
      "Epoch 7/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5113 - loss: 1.4023 - val_accuracy: 0.4642 - val_loss: 1.5701\n",
      "Epoch 8/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5270 - loss: 1.3553 - val_accuracy: 0.4710 - val_loss: 1.5408\n",
      "Epoch 9/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5411 - loss: 1.3193 - val_accuracy: 0.4766 - val_loss: 1.5418\n",
      "Epoch 10/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5483 - loss: 1.2964 - val_accuracy: 0.4790 - val_loss: 1.5512\n",
      "Epoch 11/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5611 - loss: 1.2697 - val_accuracy: 0.4774 - val_loss: 1.5721\n",
      "Epoch 12/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5759 - loss: 1.2404 - val_accuracy: 0.4862 - val_loss: 1.6025\n",
      "Epoch 13/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5828 - loss: 1.2184 - val_accuracy: 0.4854 - val_loss: 1.6019\n",
      "Epoch 14/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5946 - loss: 1.1899 - val_accuracy: 0.4894 - val_loss: 1.6310\n",
      "Epoch 15/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6071 - loss: 1.1580 - val_accuracy: 0.5006 - val_loss: 1.6145\n",
      "Epoch 16/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6096 - loss: 1.1510 - val_accuracy: 0.4858 - val_loss: 1.6078\n",
      "Epoch 17/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6171 - loss: 1.1341 - val_accuracy: 0.4956 - val_loss: 1.6352\n",
      "Epoch 18/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6292 - loss: 1.1018 - val_accuracy: 0.4962 - val_loss: 1.6381\n",
      "Epoch 19/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6331 - loss: 1.0882 - val_accuracy: 0.4886 - val_loss: 1.6686\n",
      "Epoch 20/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6386 - loss: 1.0768 - val_accuracy: 0.4948 - val_loss: 1.6456\n",
      "Epoch 21/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6499 - loss: 1.0432 - val_accuracy: 0.4902 - val_loss: 1.6932\n",
      "Epoch 22/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6557 - loss: 1.0368 - val_accuracy: 0.4952 - val_loss: 1.6895\n",
      "Epoch 23/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6612 - loss: 1.0145 - val_accuracy: 0.4922 - val_loss: 1.6869\n",
      "Epoch 24/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6622 - loss: 1.0076 - val_accuracy: 0.4942 - val_loss: 1.6771\n",
      "Epoch 25/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6642 - loss: 1.0014 - val_accuracy: 0.4962 - val_loss: 1.7652\n",
      "Epoch 26/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6718 - loss: 14.8947 - val_accuracy: 0.3914 - val_loss: 1.7927\n",
      "Epoch 27/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4743 - loss: 1.4874 - val_accuracy: 0.4354 - val_loss: 1.6258\n",
      "Epoch 28/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5205 - loss: 1.3488 - val_accuracy: 0.4474 - val_loss: 1.5882\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4706 - loss: 1.5411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5408231019973755, 0.47099998593330383]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_means = x_train.mean(axis=0)\n",
    "X_stds = x_train.std(axis=0)\n",
    "X_train_scaled = (x_train - X_means) / X_stds\n",
    "X_valid_scaled = (x_valid - X_means) / X_stds\n",
    "X_test_scaled = (x_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(checkpoint_filepath)\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4706 - loss: 1.5411\n",
      "test loss, test accuracy: [1.5408231019973755, 0.47099998593330383]\n"
     ]
    }
   ],
   "source": [
    "evauluate_model(model=model, x_test=X_valid_scaled, y_test=y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "\n",
    "for _ in range(layers):\n",
    "    model.add(keras.layers.Dense(neurons,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.Dropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "checkpoint_filepath = \"my_cifar10_alpha_dropout_model.keras\"\n",
    "model_logs_directory = \"my_model_logs\"\n",
    "\n",
    "callbacks = create_callbacks(checkpoint_filepath, model_logs_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.2803 - loss: 2.0663 - val_accuracy: 0.3898 - val_loss: 1.7209\n",
      "Epoch 2/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3864 - loss: 1.7267 - val_accuracy: 0.4350 - val_loss: 1.6076\n",
      "Epoch 3/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4328 - loss: 1.6066 - val_accuracy: 0.4506 - val_loss: 1.5836\n",
      "Epoch 4/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4697 - loss: 1.5210 - val_accuracy: 0.4796 - val_loss: 1.5388\n",
      "Epoch 5/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4928 - loss: 1.4572 - val_accuracy: 0.4818 - val_loss: 1.5226\n",
      "Epoch 6/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5165 - loss: 1.3966 - val_accuracy: 0.4878 - val_loss: 1.5265\n",
      "Epoch 7/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5355 - loss: 1.3483 - val_accuracy: 0.4804 - val_loss: 1.5193\n",
      "Epoch 8/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5538 - loss: 1.3027 - val_accuracy: 0.4916 - val_loss: 1.5149\n",
      "Epoch 9/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5687 - loss: 1.2615 - val_accuracy: 0.4894 - val_loss: 1.5391\n",
      "Epoch 10/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5807 - loss: 1.2275 - val_accuracy: 0.4890 - val_loss: 1.5431\n",
      "Epoch 11/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5938 - loss: 1.1940 - val_accuracy: 0.4990 - val_loss: 1.5675\n",
      "Epoch 12/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6044 - loss: 1.1699 - val_accuracy: 0.4992 - val_loss: 1.5655\n",
      "Epoch 13/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6122 - loss: 1.1417 - val_accuracy: 0.4814 - val_loss: 1.6059\n",
      "Epoch 14/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6240 - loss: 1.1197 - val_accuracy: 0.4940 - val_loss: 1.5916\n",
      "Epoch 15/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6335 - loss: 1.0895 - val_accuracy: 0.5012 - val_loss: 1.5971\n",
      "Epoch 16/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6385 - loss: 1.0767 - val_accuracy: 0.4954 - val_loss: 1.6316\n",
      "Epoch 17/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.6450 - loss: 1.0538 - val_accuracy: 0.4904 - val_loss: 1.6108\n",
      "Epoch 18/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.6509 - loss: 1.0397 - val_accuracy: 0.4950 - val_loss: 1.6654\n",
      "Epoch 19/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.6611 - loss: 1.0083 - val_accuracy: 0.5000 - val_loss: 1.6080\n",
      "Epoch 20/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6684 - loss: 0.9928 - val_accuracy: 0.5040 - val_loss: 1.6218\n",
      "Epoch 21/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6723 - loss: 0.9747 - val_accuracy: 0.5044 - val_loss: 1.6572\n",
      "Epoch 22/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6845 - loss: 0.9550 - val_accuracy: 0.5046 - val_loss: 1.6215\n",
      "Epoch 23/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.6868 - loss: 0.9363 - val_accuracy: 0.5062 - val_loss: 1.6803\n",
      "Epoch 24/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6931 - loss: 0.9286 - val_accuracy: 0.4990 - val_loss: 1.7041\n",
      "Epoch 25/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6934 - loss: 0.9212 - val_accuracy: 0.4972 - val_loss: 1.7294\n",
      "Epoch 26/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.7029 - loss: 0.9009 - val_accuracy: 0.4990 - val_loss: 1.7966\n",
      "Epoch 27/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7060 - loss: 0.8798 - val_accuracy: 0.4884 - val_loss: 1.6968\n",
      "Epoch 28/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.7070 - loss: 0.8776 - val_accuracy: 0.4996 - val_loss: 1.7366\n"
     ]
    }
   ],
   "source": [
    "X_means = x_train.mean(axis=0)\n",
    "X_stds = x_train.std(axis=0)\n",
    "X_train_scaled = (x_train - X_means) / X_stds\n",
    "X_valid_scaled = (x_valid - X_means) / X_stds\n",
    "X_test_scaled = (x_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4945 - loss: 1.5155\n",
      "test loss, test accuracy: [1.5148922204971313, 0.49160000681877136]\n"
     ]
    }
   ],
   "source": [
    "evauluate_model(model=model, x_test=X_valid_scaled, y_test=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIFAR 10 dataset is large, which presents a challenge for beginners such as myself. The challenge is magnified without the use of CNNs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
