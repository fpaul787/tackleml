{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network on the CIFAR10 Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar = keras.datasets.cifar10\n",
    "(x_train_full, y_train_full), (x_test, y_test) = cifar.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_full.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train_full.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train_full[1])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_full[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "x_valid = x_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for model code reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callbacks(checkpoint_filepath, model_logs_directory):\n",
    "    early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "    model_checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_best_only=True)\n",
    "    run_index = 1 # increment every time you train the model\n",
    "    run_logdir = os.path.join(os.curdir, model_logs_directory + \"/my_cifar10_logs\", \"run_bn_{:03d}\".format(run_index))\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "    callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "    return callbacks\n",
    "\n",
    "def evauluate_model(model, x_test, y_test):\n",
    "    results = model.evaluate(x_test, y_test)\n",
    "    print(\"test loss, test accuracy:\", results)\n",
    "\n",
    "def build_model(hidden_layers=1, neurons=10, learning_rate=3e03, input_shape=[8], activation=\"relu\", loss_func = \"mse\", optimizer=None):\n",
    "    if optimizer is None:\n",
    "        print(\"No optimizer given. Using SGD optimizer with 3e-3 learning rate\")\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=3e-3)\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=input_shape))\n",
    "\n",
    "    for _ in range(hidden_layers):\n",
    "        model.add(keras.layers.Dense(neurons, activation=activation))\n",
    "\n",
    "    model.add(keras.layers.Dense(10))\n",
    "\n",
    "    \n",
    "    model.compile(loss=loss_func, optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# static, throughout the notebook\n",
    "layers = 20\n",
    "neurons = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(layers):\n",
    "    model.add(keras.layers.Dense(neurons,\n",
    "                                activation=\"elu\",\n",
    "                                kernel_initializer=\"he_normal\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is He Normal Initialization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A weight initialization used with ReLU and its variants. Helps avoid issues like vanishing or exploding gradrients during training, which leads to faster convergence and better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross entropy loss function is an optimization function \n",
    "# which is used in case of training a classification model \n",
    "# which classifies the data by predicting the probability \n",
    "# of whether the data belongs to one class or the other class\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-5)\n",
    "model.compile(loss=loss_fn, optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output layer\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-5)\n",
    "model.compile(\n",
    "    loss=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = \"my_cifar10_model.keras\"\n",
    "model_logs_directory = \"my_model_logs\"\n",
    "\n",
    "callbacks = create_callbacks(checkpoint_filepath, model_logs_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=100,\n",
    "          validation_data=(x_valid, y_valid),\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(checkpoint_filepath)\n",
    "evauluate_model(model=model, x_test=x_valid, y_test=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model sucks, lets optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "for _ in range(layers):\n",
    "    model.add(keras.layers.Dense(neurons, kernel_initializer=\"he_normal\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"elu\"))\n",
    "\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "checkpoint_filepath = \"my_cifar10_bn_model.keras\"\n",
    "model_logs_directory = \"my_model_logs\"\n",
    "\n",
    "callbacks = create_callbacks(checkpoint_filepath=checkpoint_filepath, model_logs_directory=model_logs_directory)\n",
    "\n",
    "model.fit(x_train, y_train, epochs=100,\n",
    "          validation_data=(x_valid, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(checkpoint_filepath)\n",
    "model.evaluate(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evauluate_model(model=model, x_test=x_valid, y_test=y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(layers):\n",
    "    model.add(keras.layers.Dense(neurons,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=7e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "checkpoint_filepath = \"my_cifar10_selu_model.keras\"\n",
    "model_logs_directory = \"my_model_logs\"\n",
    "\n",
    "callbacks = create_callbacks(checkpoint_filepath, model_logs_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_means = x_train.mean(axis=0)\n",
    "X_stds = x_train.std(axis=0)\n",
    "X_train_scaled = (x_train - X_means) / X_stds\n",
    "X_valid_scaled = (x_valid - X_means) / X_stds\n",
    "X_test_scaled = (x_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(checkpoint_filepath)\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evauluate_model(model=model, x_test=X_valid_scaled, y_test=y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "\n",
    "for _ in range(layers):\n",
    "    model.add(keras.layers.Dense(neurons,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.Dropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "checkpoint_filepath = \"my_cifar10_alpha_dropout_model.keras\"\n",
    "model_logs_directory = \"my_model_logs\"\n",
    "\n",
    "callbacks = create_callbacks(checkpoint_filepath, model_logs_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_means = x_train.mean(axis=0)\n",
    "X_stds = x_train.std(axis=0)\n",
    "X_train_scaled = (x_train - X_means) / X_stds\n",
    "X_valid_scaled = (x_valid - X_means) / X_stds\n",
    "X_test_scaled = (x_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evauluate_model(model=model, x_test=X_valid_scaled, y_test=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIFAR 10 dataset is large, which presents a challenge for beginners such as myself. The challenge is magnified without the use of CNNs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
