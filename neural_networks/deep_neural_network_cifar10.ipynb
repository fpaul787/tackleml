{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network on the CIFAR10 Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar = keras.datasets.cifar10\n",
    "(x_train_full, y_train_full), (x_test, y_test) = cifar.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(5000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(5000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_full.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train_full.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train_full[1])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_full[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dev\\Machine_Learning\\tackleml\\env\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                activation=\"elu\",\n",
    "                                kernel_initializer=\"he_normal\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is He Normal Initialization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A weight initialization used with ReLU and its variants. Helps avoid issues like vanishing or exploding gradrients during training, which leads to faster convergence and better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross entropy loss function is an optimization function \n",
    "# which is used in case of training a classification model \n",
    "# which classifies the data by predicting the probability \n",
    "# of whether the data belongs to one class or the other class\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-5)\n",
    "model.compile(loss=loss_fn, optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "x_valid = x_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output layer\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-5)\n",
    "model.compile(\n",
    "    loss=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = \"my_cifar10_model.keras\"\n",
    "model_logs_directory = \"my_model_logs\"\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_best_only=True)\n",
    "\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, model_logs_directory + \"/my_cifar10_logs\", \"run_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.0975 - loss: 2.3113 - val_accuracy: 0.0976 - val_loss: 2.3032\n",
      "Epoch 2/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0975 - loss: 2.3010 - val_accuracy: 0.0976 - val_loss: 2.2912\n",
      "Epoch 3/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.0975 - loss: 2.2921 - val_accuracy: 0.0976 - val_loss: 2.2826\n",
      "Epoch 4/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.1595 - loss: 2.2829 - val_accuracy: 0.1832 - val_loss: 2.2753\n",
      "Epoch 5/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1801 - loss: 2.2747 - val_accuracy: 0.2010 - val_loss: 2.2630\n",
      "Epoch 6/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.1848 - loss: 2.2642 - val_accuracy: 0.1878 - val_loss: 2.2517\n",
      "Epoch 7/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1809 - loss: 2.2536 - val_accuracy: 0.1826 - val_loss: 2.2434\n",
      "Epoch 8/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1864 - loss: 2.2403 - val_accuracy: 0.2026 - val_loss: 2.2271\n",
      "Epoch 9/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1862 - loss: 2.2267 - val_accuracy: 0.1808 - val_loss: 2.2206\n",
      "Epoch 10/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1849 - loss: 2.2113 - val_accuracy: 0.1914 - val_loss: 2.1999\n",
      "Epoch 11/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1822 - loss: 2.1974 - val_accuracy: 0.1810 - val_loss: 2.1851\n",
      "Epoch 12/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1792 - loss: 2.1819 - val_accuracy: 0.1844 - val_loss: 2.1676\n",
      "Epoch 13/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1700 - loss: 2.1719 - val_accuracy: 0.1882 - val_loss: 2.1556\n",
      "Epoch 14/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1762 - loss: 2.1549 - val_accuracy: 0.2002 - val_loss: 2.1355\n",
      "Epoch 15/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1906 - loss: 2.1403 - val_accuracy: 0.1952 - val_loss: 2.1292\n",
      "Epoch 16/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1909 - loss: 2.1291 - val_accuracy: 0.2048 - val_loss: 2.1193\n",
      "Epoch 17/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1919 - loss: 2.1162 - val_accuracy: 0.1946 - val_loss: 2.1063\n",
      "Epoch 18/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1926 - loss: 2.1076 - val_accuracy: 0.1928 - val_loss: 2.1063\n",
      "Epoch 19/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.1909 - loss: 2.0945 - val_accuracy: 0.1814 - val_loss: 2.1305\n",
      "Epoch 20/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1880 - loss: 2.0896 - val_accuracy: 0.1994 - val_loss: 2.0778\n",
      "Epoch 21/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1887 - loss: 2.0750 - val_accuracy: 0.1964 - val_loss: 2.0825\n",
      "Epoch 22/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1894 - loss: 2.0660 - val_accuracy: 0.1966 - val_loss: 2.0628\n",
      "Epoch 23/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.1958 - loss: 2.0567 - val_accuracy: 0.1996 - val_loss: 2.0613\n",
      "Epoch 24/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.1948 - loss: 2.0535 - val_accuracy: 0.1992 - val_loss: 2.0473\n",
      "Epoch 25/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.1920 - loss: 2.0453 - val_accuracy: 0.2030 - val_loss: 2.0462\n",
      "Epoch 26/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1959 - loss: 2.0385 - val_accuracy: 0.2018 - val_loss: 2.0337\n",
      "Epoch 27/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1927 - loss: 2.0363 - val_accuracy: 0.2076 - val_loss: 2.0280\n",
      "Epoch 28/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1962 - loss: 2.0224 - val_accuracy: 0.2038 - val_loss: 2.0260\n",
      "Epoch 29/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1958 - loss: 2.0202 - val_accuracy: 0.1980 - val_loss: 2.0261\n",
      "Epoch 30/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1946 - loss: 2.0178 - val_accuracy: 0.2054 - val_loss: 2.0226\n",
      "Epoch 31/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.1976 - loss: 2.0061 - val_accuracy: 0.2066 - val_loss: 2.0147\n",
      "Epoch 32/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.1977 - loss: 1.9990 - val_accuracy: 0.2030 - val_loss: 2.0035\n",
      "Epoch 33/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1979 - loss: 1.9927 - val_accuracy: 0.2052 - val_loss: 2.0017\n",
      "Epoch 34/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1997 - loss: 1.9842 - val_accuracy: 0.2056 - val_loss: 2.0047\n",
      "Epoch 35/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1993 - loss: 1.9778 - val_accuracy: 0.2080 - val_loss: 1.9985\n",
      "Epoch 36/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2018 - loss: 1.9710 - val_accuracy: 0.2052 - val_loss: 1.9917\n",
      "Epoch 37/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2034 - loss: 1.9650 - val_accuracy: 0.2080 - val_loss: 1.9943\n",
      "Epoch 38/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2022 - loss: 1.9592 - val_accuracy: 0.2082 - val_loss: 2.0049\n",
      "Epoch 39/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2035 - loss: 1.9553 - val_accuracy: 0.2060 - val_loss: 1.9878\n",
      "Epoch 40/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2026 - loss: 1.9497 - val_accuracy: 0.2112 - val_loss: 1.9863\n",
      "Epoch 41/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2070 - loss: 1.9437 - val_accuracy: 0.2098 - val_loss: 1.9876\n",
      "Epoch 42/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2078 - loss: 1.9381 - val_accuracy: 0.2118 - val_loss: 1.9804\n",
      "Epoch 43/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.2083 - loss: 1.9325 - val_accuracy: 0.2098 - val_loss: 1.9869\n",
      "Epoch 44/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.2102 - loss: 1.9284 - val_accuracy: 0.2144 - val_loss: 1.9848\n",
      "Epoch 45/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.2147 - loss: 1.9221 - val_accuracy: 0.2144 - val_loss: 1.9848\n",
      "Epoch 46/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.2115 - loss: 1.9179 - val_accuracy: 0.2166 - val_loss: 1.9696\n",
      "Epoch 47/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.2165 - loss: 1.9118 - val_accuracy: 0.2122 - val_loss: 1.9751\n",
      "Epoch 48/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2154 - loss: 1.9077 - val_accuracy: 0.2102 - val_loss: 1.9766\n",
      "Epoch 49/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2184 - loss: 1.9018 - val_accuracy: 0.2170 - val_loss: 1.9752\n",
      "Epoch 50/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2166 - loss: 1.8990 - val_accuracy: 0.2142 - val_loss: 1.9745\n",
      "Epoch 51/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2188 - loss: 1.8961 - val_accuracy: 0.2166 - val_loss: 1.9728\n",
      "Epoch 52/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2207 - loss: 1.8902 - val_accuracy: 0.2176 - val_loss: 1.9706\n",
      "Epoch 53/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2242 - loss: 1.8843 - val_accuracy: 0.2184 - val_loss: 1.9699\n",
      "Epoch 54/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.2315 - loss: 1.8821 - val_accuracy: 0.2172 - val_loss: 1.9727\n",
      "Epoch 55/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2337 - loss: 1.8761 - val_accuracy: 0.2146 - val_loss: 1.9764\n",
      "Epoch 56/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2430 - loss: 1.8727 - val_accuracy: 0.2140 - val_loss: 1.9639\n",
      "Epoch 57/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.2432 - loss: 1.8665 - val_accuracy: 0.2152 - val_loss: 1.9673\n",
      "Epoch 58/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.2448 - loss: 1.8639 - val_accuracy: 0.2174 - val_loss: 1.9675\n",
      "Epoch 59/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.2489 - loss: 1.8595 - val_accuracy: 0.2192 - val_loss: 1.9647\n",
      "Epoch 60/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.2525 - loss: 1.8528 - val_accuracy: 0.2148 - val_loss: 1.9613\n",
      "Epoch 61/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2556 - loss: 1.8476 - val_accuracy: 0.2248 - val_loss: 1.9658\n",
      "Epoch 62/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2550 - loss: 1.8456 - val_accuracy: 0.2290 - val_loss: 1.9647\n",
      "Epoch 63/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.2640 - loss: 1.8384 - val_accuracy: 0.2372 - val_loss: 1.9594\n",
      "Epoch 64/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.2726 - loss: 1.8363 - val_accuracy: 0.2436 - val_loss: 1.9613\n",
      "Epoch 65/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.2764 - loss: 1.8348 - val_accuracy: 0.2392 - val_loss: 1.9622\n",
      "Epoch 66/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.2770 - loss: 1.8279 - val_accuracy: 0.2508 - val_loss: 1.9458\n",
      "Epoch 67/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.2830 - loss: 1.8226 - val_accuracy: 0.2540 - val_loss: 1.9604\n",
      "Epoch 68/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.2856 - loss: 1.8161 - val_accuracy: 0.2594 - val_loss: 1.9489\n",
      "Epoch 69/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.2892 - loss: 1.8109 - val_accuracy: 0.2466 - val_loss: 1.9445\n",
      "Epoch 70/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2924 - loss: 1.8064 - val_accuracy: 0.2498 - val_loss: 1.9536\n",
      "Epoch 71/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2954 - loss: 1.8014 - val_accuracy: 0.2520 - val_loss: 1.9527\n",
      "Epoch 72/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3030 - loss: 1.7944 - val_accuracy: 0.2544 - val_loss: 1.9453\n",
      "Epoch 73/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3003 - loss: 1.7935 - val_accuracy: 0.2652 - val_loss: 1.9349\n",
      "Epoch 74/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3057 - loss: 1.7857 - val_accuracy: 0.2590 - val_loss: 1.9488\n",
      "Epoch 75/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3087 - loss: 1.7789 - val_accuracy: 0.2726 - val_loss: 1.9339\n",
      "Epoch 76/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.3108 - loss: 1.7760 - val_accuracy: 0.2664 - val_loss: 1.9424\n",
      "Epoch 77/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3111 - loss: 1.7691 - val_accuracy: 0.2708 - val_loss: 1.9405\n",
      "Epoch 78/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3161 - loss: 1.7628 - val_accuracy: 0.2748 - val_loss: 1.9307\n",
      "Epoch 79/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3184 - loss: 1.7584 - val_accuracy: 0.2760 - val_loss: 1.9311\n",
      "Epoch 80/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3202 - loss: 1.7503 - val_accuracy: 0.2692 - val_loss: 1.9405\n",
      "Epoch 81/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3242 - loss: 1.7412 - val_accuracy: 0.2812 - val_loss: 1.9213\n",
      "Epoch 82/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3255 - loss: 1.7405 - val_accuracy: 0.2732 - val_loss: 1.9318\n",
      "Epoch 83/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3267 - loss: 1.7328 - val_accuracy: 0.2748 - val_loss: 1.9285\n",
      "Epoch 84/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3295 - loss: 1.7252 - val_accuracy: 0.2638 - val_loss: 1.9453\n",
      "Epoch 85/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3354 - loss: 1.7184 - val_accuracy: 0.2780 - val_loss: 1.9274\n",
      "Epoch 86/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3342 - loss: 1.7100 - val_accuracy: 0.2804 - val_loss: 1.9171\n",
      "Epoch 87/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3375 - loss: 1.7028 - val_accuracy: 0.2780 - val_loss: 1.9158\n",
      "Epoch 88/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3383 - loss: 1.6947 - val_accuracy: 0.2820 - val_loss: 1.9180\n",
      "Epoch 89/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3431 - loss: 1.6861 - val_accuracy: 0.2824 - val_loss: 1.9261\n",
      "Epoch 90/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3481 - loss: 1.6774 - val_accuracy: 0.2850 - val_loss: 1.9083\n",
      "Epoch 91/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3490 - loss: 1.6708 - val_accuracy: 0.2880 - val_loss: 1.9111\n",
      "Epoch 92/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3513 - loss: 1.6614 - val_accuracy: 0.2910 - val_loss: 1.9050\n",
      "Epoch 93/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3521 - loss: 1.6613 - val_accuracy: 0.2862 - val_loss: 1.9154\n",
      "Epoch 94/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3534 - loss: 1.6541 - val_accuracy: 0.2942 - val_loss: 1.8906\n",
      "Epoch 95/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.3558 - loss: 1.6447 - val_accuracy: 0.2864 - val_loss: 1.9232\n",
      "Epoch 96/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3546 - loss: 1.6430 - val_accuracy: 0.2798 - val_loss: 1.9174\n",
      "Epoch 97/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3574 - loss: 1.6350 - val_accuracy: 0.2922 - val_loss: 1.9043\n",
      "Epoch 98/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3624 - loss: 1.6256 - val_accuracy: 0.2852 - val_loss: 1.9179\n",
      "Epoch 99/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3644 - loss: 1.6171 - val_accuracy: 0.2876 - val_loss: 1.9120\n",
      "Epoch 100/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3643 - loss: 1.6090 - val_accuracy: 0.2858 - val_loss: 1.9156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x21b87e39a50>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100,\n",
    "          validation_data=(x_valid, y_valid),\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for model code reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callbacks(checkpoint_filepath, model_logs_directory):\n",
    "    early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "    model_checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_best_only=True)\n",
    "    run_index = 1 # increment every time you train the model\n",
    "    run_logdir = os.path.join(os.curdir, model_logs_directory + \"/my_cifar10_logs\", \"run_bn_{:03d}\".format(run_index))\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "    callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "    return callbacks\n",
    "\n",
    "def evauluate_model(model, x_test, y_test):\n",
    "    results = model.evaluate(x_test, y_test)\n",
    "    print(\"test loss, test accuracy:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2984 - loss: 1.8913\n",
      "test loss, test accuracy: [1.8906466960906982, 0.29420000314712524]\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(checkpoint_filepath)\n",
    "evauluate_model(model=model, x_test=x_valid, y_test=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model sucks, lets optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dev\\Machine_Learning\\tackleml\\env\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 9ms/step - accuracy: 0.2861 - loss: 1.9872 - val_accuracy: 0.4060 - val_loss: 1.6609\n",
      "Epoch 2/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.3978 - loss: 1.6803 - val_accuracy: 0.4392 - val_loss: 1.5756\n",
      "Epoch 3/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.4379 - loss: 1.5841 - val_accuracy: 0.4492 - val_loss: 1.5477\n",
      "Epoch 4/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.4671 - loss: 1.5085 - val_accuracy: 0.4698 - val_loss: 1.5077\n",
      "Epoch 5/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.4909 - loss: 1.4457 - val_accuracy: 0.4714 - val_loss: 1.5029\n",
      "Epoch 6/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5121 - loss: 1.3896 - val_accuracy: 0.4814 - val_loss: 1.5002\n",
      "Epoch 7/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5319 - loss: 1.3383 - val_accuracy: 0.4822 - val_loss: 1.5056\n",
      "Epoch 8/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5501 - loss: 1.2910 - val_accuracy: 0.4790 - val_loss: 1.5198\n",
      "Epoch 9/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5635 - loss: 1.2490 - val_accuracy: 0.4766 - val_loss: 1.5609\n",
      "Epoch 10/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5778 - loss: 1.2122 - val_accuracy: 0.4700 - val_loss: 1.5827\n",
      "Epoch 11/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5903 - loss: 1.1760 - val_accuracy: 0.4734 - val_loss: 1.6013\n",
      "Epoch 12/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6042 - loss: 1.1396 - val_accuracy: 0.4680 - val_loss: 1.6289\n",
      "Epoch 13/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6173 - loss: 1.1041 - val_accuracy: 0.4700 - val_loss: 1.6512\n",
      "Epoch 14/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6256 - loss: 1.0726 - val_accuracy: 0.4632 - val_loss: 1.6828\n",
      "Epoch 15/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6399 - loss: 1.0471 - val_accuracy: 0.4632 - val_loss: 1.7126\n",
      "Epoch 16/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6446 - loss: 1.0211 - val_accuracy: 0.4656 - val_loss: 1.7439\n",
      "Epoch 17/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6524 - loss: 1.0080 - val_accuracy: 0.4692 - val_loss: 1.7909\n",
      "Epoch 18/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6663 - loss: 0.9710 - val_accuracy: 0.4680 - val_loss: 1.7996\n",
      "Epoch 19/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6742 - loss: 0.9447 - val_accuracy: 0.4654 - val_loss: 1.8238\n",
      "Epoch 20/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6865 - loss: 0.9185 - val_accuracy: 0.4744 - val_loss: 1.8506\n",
      "Epoch 21/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6889 - loss: 0.9030 - val_accuracy: 0.4676 - val_loss: 1.8521\n",
      "Epoch 22/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.7002 - loss: 0.8710 - val_accuracy: 0.4660 - val_loss: 1.9326\n",
      "Epoch 23/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7070 - loss: 0.8527 - val_accuracy: 0.4706 - val_loss: 1.9263\n",
      "Epoch 24/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.7144 - loss: 0.8335 - val_accuracy: 0.4752 - val_loss: 1.9451\n",
      "Epoch 25/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.7174 - loss: 0.8154 - val_accuracy: 0.4710 - val_loss: 1.9552\n",
      "Epoch 26/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7247 - loss: 0.7943 - val_accuracy: 0.4772 - val_loss: 2.0091\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4867 - loss: 1.4962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.50016188621521, 0.4814000129699707]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initializer=\"he_normal\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"elu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "checkpoint_filepath = \"my_cifar10_bn_model.keras\"\n",
    "model_logs_directory = \"my_model_logs\"\n",
    "\n",
    "callbacks = create_callbacks(checkpoint_filepath=checkpoint_filepath, model_logs_directory=model_logs_directory)\n",
    "\n",
    "model.fit(x_train, y_train, epochs=100,\n",
    "          validation_data=(x_valid, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(checkpoint_filepath)\n",
    "model.evaluate(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4652 - loss: 1.5239\n",
      "test loss, test accuracy: [1.516983151435852, 0.460999995470047]\n"
     ]
    }
   ],
   "source": [
    "evauluate_model(model=model, x_test=x_valid, y_test=y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dev\\Machine_Learning\\tackleml\\env\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=7e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "checkpoint_filepath = \"my_cifar10_selu_model.keras\"\n",
    "model_logs_directory = \"my_model_logs\"\n",
    "\n",
    "callbacks = create_callbacks(checkpoint_filepath, model_logs_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.2625 - loss: 2.0683 - val_accuracy: 0.3526 - val_loss: 1.8373\n",
      "Epoch 2/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3691 - loss: 1.7612 - val_accuracy: 0.4058 - val_loss: 1.6801\n",
      "Epoch 3/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4157 - loss: 1.6532 - val_accuracy: 0.4342 - val_loss: 1.6456\n",
      "Epoch 4/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4464 - loss: 1.5839 - val_accuracy: 0.4476 - val_loss: 1.6015\n",
      "Epoch 5/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4745 - loss: 1.5200 - val_accuracy: 0.4420 - val_loss: 1.5798\n",
      "Epoch 6/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4874 - loss: 1.4790 - val_accuracy: 0.4604 - val_loss: 1.5910\n",
      "Epoch 7/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.5042 - loss: 1.4275 - val_accuracy: 0.4672 - val_loss: 1.5508\n",
      "Epoch 8/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5198 - loss: 1.3874 - val_accuracy: 0.4756 - val_loss: 1.5223\n",
      "Epoch 9/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5359 - loss: 1.3474 - val_accuracy: 0.4760 - val_loss: 1.5536\n",
      "Epoch 10/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5493 - loss: 1.3153 - val_accuracy: 0.4838 - val_loss: 1.5313\n",
      "Epoch 11/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5552 - loss: 1.3022 - val_accuracy: 0.4742 - val_loss: 1.5884\n",
      "Epoch 12/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5676 - loss: 1.2678 - val_accuracy: 0.4826 - val_loss: 1.5713\n",
      "Epoch 13/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5755 - loss: 1.2380 - val_accuracy: 0.4818 - val_loss: 1.5717\n",
      "Epoch 14/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5862 - loss: 1.2222 - val_accuracy: 0.4952 - val_loss: 1.5803\n",
      "Epoch 15/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5910 - loss: 1.2054 - val_accuracy: 0.4656 - val_loss: 1.6777\n",
      "Epoch 16/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6003 - loss: 1.1802 - val_accuracy: 0.4842 - val_loss: 1.6211\n",
      "Epoch 17/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6081 - loss: 1.1606 - val_accuracy: 0.4904 - val_loss: 1.6107\n",
      "Epoch 18/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6137 - loss: 1.1488 - val_accuracy: 0.4820 - val_loss: 1.6167\n",
      "Epoch 19/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.6257 - loss: 1.1136 - val_accuracy: 0.4878 - val_loss: 1.6279\n",
      "Epoch 20/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6310 - loss: 1.1084 - val_accuracy: 0.4808 - val_loss: 1.5936\n",
      "Epoch 21/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6389 - loss: 1.0890 - val_accuracy: 0.4928 - val_loss: 1.6327\n",
      "Epoch 22/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6383 - loss: 1.0783 - val_accuracy: 0.4980 - val_loss: 1.6340\n",
      "Epoch 23/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6334 - loss: 1.1029 - val_accuracy: 0.4974 - val_loss: 1.6079\n",
      "Epoch 24/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6547 - loss: 1.0393 - val_accuracy: 0.4972 - val_loss: 1.6531\n",
      "Epoch 25/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6609 - loss: 1.0238 - val_accuracy: 0.4868 - val_loss: 1.6765\n",
      "Epoch 26/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6520 - loss: 1.2618 - val_accuracy: 0.4422 - val_loss: 1.6638\n",
      "Epoch 27/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5551 - loss: 1.2938 - val_accuracy: 0.4824 - val_loss: 1.5942\n",
      "Epoch 28/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6011 - loss: 1.1683 - val_accuracy: 0.5000 - val_loss: 1.5867\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4854 - loss: 1.5147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.522348165512085, 0.475600004196167]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_means = x_train.mean(axis=0)\n",
    "X_stds = x_train.std(axis=0)\n",
    "X_train_scaled = (x_train - X_means) / X_stds\n",
    "X_valid_scaled = (x_valid - X_means) / X_stds\n",
    "X_test_scaled = (x_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(checkpoint_filepath)\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4854 - loss: 1.5147\n",
      "test loss, test accuracy: [1.522348165512085, 0.475600004196167]\n"
     ]
    }
   ],
   "source": [
    "evauluate_model(model=model, x_test=X_valid_scaled, y_test=y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dev\\Machine_Learning\\tackleml\\env\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.Dropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "checkpoint_filepath = \"my_cifar10_alpha_dropout_model.keras\"\n",
    "model_logs_directory = \"my_model_logs\"\n",
    "\n",
    "callbacks = create_callbacks(checkpoint_filepath, model_logs_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6ms/step - accuracy: 0.2591 - loss: 2.1060 - val_accuracy: 0.3786 - val_loss: 1.7801\n",
      "Epoch 2/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.3799 - loss: 1.7467 - val_accuracy: 0.4228 - val_loss: 1.6648\n",
      "Epoch 3/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4286 - loss: 1.6180 - val_accuracy: 0.4440 - val_loss: 1.6051\n",
      "Epoch 4/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4586 - loss: 1.5419 - val_accuracy: 0.4688 - val_loss: 1.5281\n",
      "Epoch 5/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4899 - loss: 1.4677 - val_accuracy: 0.4734 - val_loss: 1.5451\n",
      "Epoch 6/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5110 - loss: 1.4140 - val_accuracy: 0.4770 - val_loss: 1.5373\n",
      "Epoch 7/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.5327 - loss: 1.3629 - val_accuracy: 0.4854 - val_loss: 1.5212\n",
      "Epoch 8/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5483 - loss: 1.3125 - val_accuracy: 0.4766 - val_loss: 1.5690\n",
      "Epoch 9/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5590 - loss: 1.2871 - val_accuracy: 0.4870 - val_loss: 1.5439\n",
      "Epoch 10/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5766 - loss: 1.2450 - val_accuracy: 0.4886 - val_loss: 1.5532\n",
      "Epoch 11/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.5893 - loss: 1.2163 - val_accuracy: 0.4776 - val_loss: 1.5567\n",
      "Epoch 12/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.6019 - loss: 1.1757 - val_accuracy: 0.4814 - val_loss: 1.6019\n",
      "Epoch 13/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6058 - loss: 1.1595 - val_accuracy: 0.4920 - val_loss: 1.5586\n",
      "Epoch 14/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6202 - loss: 1.1281 - val_accuracy: 0.4862 - val_loss: 1.5942\n",
      "Epoch 15/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6287 - loss: 1.1087 - val_accuracy: 0.4914 - val_loss: 1.5910\n",
      "Epoch 16/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.6334 - loss: 1.0936 - val_accuracy: 0.4904 - val_loss: 1.6272\n",
      "Epoch 17/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.6451 - loss: 1.0709 - val_accuracy: 0.4960 - val_loss: 1.6460\n",
      "Epoch 18/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6508 - loss: 1.0540 - val_accuracy: 0.4968 - val_loss: 1.6365\n",
      "Epoch 19/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6587 - loss: 1.0286 - val_accuracy: 0.4792 - val_loss: 1.7224\n",
      "Epoch 20/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6658 - loss: 1.0097 - val_accuracy: 0.4916 - val_loss: 1.6576\n",
      "Epoch 21/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6728 - loss: 0.9902 - val_accuracy: 0.4994 - val_loss: 1.6578\n",
      "Epoch 22/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6795 - loss: 0.9698 - val_accuracy: 0.4944 - val_loss: 1.7097\n",
      "Epoch 23/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6841 - loss: 0.9646 - val_accuracy: 0.4974 - val_loss: 1.6855\n",
      "Epoch 24/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6904 - loss: 0.9429 - val_accuracy: 0.4932 - val_loss: 1.6830\n",
      "Epoch 25/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6919 - loss: 0.9319 - val_accuracy: 0.4922 - val_loss: 1.6739\n",
      "Epoch 26/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6975 - loss: 0.9226 - val_accuracy: 0.5002 - val_loss: 1.7013\n",
      "Epoch 27/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.7022 - loss: 0.9088 - val_accuracy: 0.4982 - val_loss: 1.7096\n"
     ]
    }
   ],
   "source": [
    "X_means = x_train.mean(axis=0)\n",
    "X_stds = x_train.std(axis=0)\n",
    "X_train_scaled = (x_train - X_means) / X_stds\n",
    "X_valid_scaled = (x_valid - X_means) / X_stds\n",
    "X_test_scaled = (x_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4838 - loss: 1.5302\n",
      "test loss, test accuracy: [1.5211951732635498, 0.48539999127388]\n"
     ]
    }
   ],
   "source": [
    "evauluate_model(model=model, x_test=X_valid_scaled, y_test=y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
